{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22142d03-67ac-4dab-ba27-9f22690244d5",
   "metadata": {},
   "source": [
    "# ä¸Šä¸‹æ–‡å·¥ç¨‹\n",
    "\n",
    "[ä¸Šä¸‹æ–‡å·¥ç¨‹](https://docs.langchain.com/oss/python/langchain/context-engineering)ï¼ˆContext Engineeringï¼‰å¯¹äº Agent å¾—å‡ºæ­£ç¡®çš„ç»“æœè‡³å…³é‡è¦ã€‚æ¨¡å‹å›ç­”ä¸å¥½ï¼Œå¾ˆå¤šæ—¶å€™ä¸æ˜¯å› ä¸ºèƒ½åŠ›ä¸è¶³ï¼Œè€Œæ˜¯å› ä¸ºæ²¡æœ‰è·å¾—è¶³ä»¥æ¨æ–­å‡ºæ­£ç¡®ç»“æœçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚é€šè¿‡ä¸Šä¸‹æ–‡å·¥ç¨‹ï¼Œå¢å¼º Agent è·å–å’Œç®¡ç†ä¸Šä¸‹æ–‡çš„èƒ½åŠ›ï¼Œæ˜¯å¾ˆæœ‰å¿…è¦çš„ã€‚\n",
    "\n",
    "**LangGraph å°†ä¸Šä¸‹æ–‡åˆ†ä¸ºä¸‰ç§ç±»å‹ï¼š**\n",
    "\n",
    "- æ¨¡å‹ä¸Šä¸‹æ–‡ï¼ˆModel Contextï¼‰\n",
    "- å·¥å…·ä¸Šä¸‹æ–‡ï¼ˆTool Contextï¼‰\n",
    "- ç”Ÿå‘½å‘¨æœŸä¸Šä¸‹æ–‡ï¼ˆLife-cycle Contextï¼‰\n",
    "\n",
    "æ— è®ºå“ªç§ Contextï¼Œéƒ½éœ€è¦å®šä¹‰å®ƒçš„ Schemaã€‚åœ¨è¿™æ–¹é¢ï¼ŒLangGraph æä¾›äº†ç›¸å½“é«˜çš„è‡ªç”±åº¦ï¼Œä½ å¯ä»¥ä½¿ç”¨ `dataclasses`ã€`pydantic`ã€`TypedDict` è¿™äº›åŒ…çš„ä»»æ„ä¸€ä¸ªåˆ›å»ºä½ çš„ Context Schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4412b776-1f74-41e8-9444-f1724bcff581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipynbname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54a92bc3-bd5e-4ad9-8b4a-2ae1d0f171cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import sqlite3\n",
    "\n",
    "from typing import Callable\n",
    "from dotenv import load_dotenv\n",
    "from dataclasses import dataclass\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import dynamic_prompt, wrap_model_call, ModelRequest, ModelResponse, SummarizationMiddleware\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langgraph.store.sqlite import SqliteStore\n",
    "\n",
    "# åŠ è½½æ¨¡å‹é…ç½®\n",
    "_ = load_dotenv()\n",
    "\n",
    "# åŠ è½½æ¨¡å‹\n",
    "llm = ChatOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n",
    "    model=\"qwen3-coder-plus\",\n",
    "    temperature=0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833f5631-a9f6-40d5-9e57-d652e347c993",
   "metadata": {},
   "source": [
    "## ä¸€ã€åŠ¨æ€ä¿®æ”¹ç³»ç»Ÿæç¤ºè¯\n",
    "\n",
    "ä¸Šä¸‹æ–‡å·¥ç¨‹ä¸å‰åºç« èŠ‚çš„ä¸­é—´ä»¶ï¼ˆmiddlewareï¼‰å’Œè®°å¿†ï¼ˆmemoryï¼‰å¯†ä¸å¯åˆ†ã€‚ä¸Šä¸‹æ–‡çš„å…·ä½“å®ç°ä¾èµ–ä¸­é—´ä»¶ï¼Œè€Œä¸Šä¸‹æ–‡çš„å­˜å‚¨åˆ™ä¾èµ–è®°å¿†ç³»ç»Ÿã€‚å…·ä½“æ¥è®²ï¼ŒLangGraph é¢„ç½®äº† `@dynamic_prompt` ä¸­é—´ä»¶ï¼Œç”¨äºåŠ¨æ€ä¿®æ”¹ç³»ç»Ÿæç¤ºè¯ã€‚\n",
    "\n",
    "æ—¢ç„¶æ˜¯åŠ¨æ€ä¿®æ”¹ï¼Œè‚¯å®šéœ€è¦æŸä¸ªæ¡ä»¶æ¥è§¦å‘ä¿®æ”¹ã€‚é™¤äº†å¼€å‘è§¦å‘é€»è¾‘ï¼Œæˆ‘ä»¬è¿˜éœ€è¦ä»æ™ºèƒ½ä½“ä¸­è·å–è§¦å‘é€»è¾‘æ‰€éœ€çš„å³æ—¶å˜é‡ã€‚è¿™äº›å˜é‡é€šå¸¸å­˜å‚¨åœ¨ä»¥ä¸‹ä¸‰ä¸ªå­˜å‚¨ä»‹è´¨ä¸­ï¼š\n",
    "\n",
    "- è¿è¡Œæ—¶ï¼ˆRuntimeï¼‰- æ‰€æœ‰èŠ‚ç‚¹å…±äº«ä¸€ä¸ª Runtimeã€‚åŒä¸€æ—¶åˆ»ï¼Œæ‰€æœ‰èŠ‚ç‚¹å–åˆ°çš„ Runtime çš„å€¼æ˜¯ç›¸åŒçš„ã€‚ä¸€èˆ¬ç”¨äºå­˜å‚¨æ—¶æ•ˆæ€§è¦æ±‚è¾ƒé«˜çš„ä¿¡æ¯ã€‚\n",
    "- çŸ­æœŸè®°å¿†ï¼ˆStateï¼‰- åœ¨èŠ‚ç‚¹ä¹‹é—´æŒ‰é¡ºåºä¼ é€’ï¼Œæ¯ä¸ªèŠ‚ç‚¹æ¥æ”¶ä¸Šä¸€ä¸ªèŠ‚ç‚¹å¤„ç†åçš„ Stateã€‚ä¸»è¦ç”¨äºå­˜å‚¨ Prompt å’Œ AI Messageã€‚\n",
    "- é•¿æœŸè®°å¿†ï¼ˆStoreï¼‰- è´Ÿè´£æŒä¹…åŒ–å­˜å‚¨ï¼Œå¯ä»¥è·¨ Workflow / Agent ä¿å­˜ä¿¡æ¯ã€‚å¯ä»¥ç”¨æ¥å­˜ç”¨æˆ·åå¥½ã€ä»¥å‰ç®—è¿‡çš„ç»Ÿè®¡å€¼ç­‰ã€‚\n",
    "\n",
    "ä»¥ä¸‹ä¸‰ä¸ªä¾‹å­ï¼Œåˆ†åˆ«æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æ¥è‡ª Runtimeã€Stateã€Store ä¸­çš„ä¸Šä¸‹æ–‡ï¼Œç¼–å†™è§¦å‘æ¡ä»¶ã€‚\n",
    "\n",
    "### 1ï¼‰ä½¿ç”¨ `State` ç®¡ç†ä¸Šä¸‹æ–‡\n",
    "\n",
    "åˆ©ç”¨ `State` ä¸­è•´å«çš„ä¿¡æ¯æ“çºµ system prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a9eb1bf-37b9-4aab-a8f3-0e1cffca6eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful assistant.\n",
      "This is a long conversation - be extra concise.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "å¹¿å·ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "å¹¿å·å¤©æ°”å¾ˆå¥½\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "åƒç‚¹ä»€ä¹ˆå¥½å‘¢\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "è¦ä¸è¦åƒé¦™èŒ…é³—é±¼ç…²\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "é¦™èŒ…æ˜¯ä»€ä¹ˆ\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "é¦™èŒ…åˆåæŸ æª¬è‰ï¼Œå¸¸è§äºæ³°å¼å†¬é˜´åŠŸæ±¤ã€è¶Šå—çƒ¤è‚‰\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "auv é‚£è¿˜ç­‰ä»€ä¹ˆï¼Œå’±åƒå»å§\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "å¥½ä¸»æ„ï¼é¦™èŒ…é³—é±¼ç…²å¬èµ·æ¥å¾ˆç¾å‘³ï¼Œèµ°å§ï¼\n"
     ]
    }
   ],
   "source": [
    "@dynamic_prompt\n",
    "def state_aware_prompt(request: ModelRequest) -> str:\n",
    "    # request.messages is a shortcut for request.state[\"messages\"]\n",
    "    message_count = len(request.messages)\n",
    "\n",
    "    base = \"You are a helpful assistant.\"\n",
    "\n",
    "    if message_count > 6:\n",
    "        base += \"\\nThis is a long conversation - be extra concise.\"\n",
    "\n",
    "    # ä¸´æ—¶æ‰“å°baseçœ‹æ•ˆæœ\n",
    "    print(base)\n",
    "\n",
    "    return base\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    middleware=[state_aware_prompt]\n",
    ")\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"å¹¿å·ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"å¹¿å·å¤©æ°”å¾ˆå¥½\"},\n",
    "        {\"role\": \"user\", \"content\": \"åƒç‚¹ä»€ä¹ˆå¥½å‘¢\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"è¦ä¸è¦åƒé¦™èŒ…é³—é±¼ç…²\"},\n",
    "        {\"role\": \"user\", \"content\": \"é¦™èŒ…æ˜¯ä»€ä¹ˆ\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"é¦™èŒ…åˆåæŸ æª¬è‰ï¼Œå¸¸è§äºæ³°å¼å†¬é˜´åŠŸæ±¤ã€è¶Šå—çƒ¤è‚‰\"},\n",
    "        {\"role\": \"user\", \"content\": \"auv é‚£è¿˜ç­‰ä»€ä¹ˆï¼Œå’±åƒå»å§\"},\n",
    "    ]},\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9c9a5d-90a9-464d-b0dd-bc0b383ce149",
   "metadata": {},
   "source": [
    "æŠŠ `message_count > 6` é‡Œçš„ 6 æ”¹æˆ 7ï¼Œè¯•è¯•çœ‹ä¼šå‘ç”Ÿä»€ä¹ˆã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f4c6d6-cea7-448a-ae42-33bcc64b77a3",
   "metadata": {},
   "source": [
    "### 2ï¼‰ä½¿ç”¨ `Store` ç®¡ç†ä¸Šä¸‹æ–‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e98294b9-7a56-499b-a190-e0181e2d6a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Context:\n",
    "    user_id: str\n",
    "\n",
    "@dynamic_prompt\n",
    "def store_aware_prompt(request: ModelRequest) -> str:\n",
    "    user_id = request.runtime.context.user_id\n",
    "\n",
    "    # Read from Store: get user preferences\n",
    "    store = request.runtime.store\n",
    "    user_prefs = store.get((\"preferences\",), user_id)\n",
    "\n",
    "    base = \"You are a helpful assistant.\"\n",
    "\n",
    "    if user_prefs:\n",
    "        style = user_prefs.value.get(\"communication_style\", \"balanced\")\n",
    "        base += f\"\\nUser prefers {style} responses.\"\n",
    "\n",
    "    return base\n",
    "\n",
    "store = InMemoryStore()\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    middleware=[store_aware_prompt],\n",
    "    context_schema=Context,\n",
    "    store=store,\n",
    ")\n",
    "\n",
    "# é¢„ç½®ä¸¤æ¡åå¥½ä¿¡æ¯\n",
    "store.put((\"preferences\",), \"user_1\", {\"communication_style\": \"Chinese\"})\n",
    "store.put((\"preferences\",), \"user_2\", {\"communication_style\": \"Korean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "509b7bc4-1a3b-4b32-9afe-3db4894c1ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a helpful assistant. Please be extra concise.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is a \"hold short line\"?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "\"_hold short line_\" æ˜¯èˆªç©ºæœ¯è¯­ï¼ŒæŒ‡è·‘é“å…¥å£å‰çš„åœæ­¢çº¿ã€‚é£è¡Œå‘˜å¿…é¡»åœ¨æ­¤çº¿å‰åœä¸‹é£æœºï¼Œç­‰å¾…ç©ºä¸­äº¤é€šç®¡åˆ¶è®¸å¯åæ‰èƒ½è¿›å…¥è·‘é“èµ·é£ã€‚\n",
      "\n",
      "åœ¨åœ°é¢æ»‘è¡Œæ—¶ï¼Œè¿™æ˜¯é‡è¦çš„å®‰å…¨æ ‡å¿—ã€‚\n"
     ]
    }
   ],
   "source": [
    "# ç”¨æˆ·1å–œæ¬¢ä¸­æ–‡å›å¤\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant. Please be extra concise.\"},\n",
    "        {\"role\": \"user\", \"content\": 'What is a \"hold short line\"?'}\n",
    "    ]},\n",
    "    context=Context(user_id=\"user_1\"),\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "288d2a65-b328-4448-a155-222afc84f3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a helpful assistant. Please be extra concise.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is a \"hold short line\"?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "\"í™€ë“œ ì‡¼íŠ¸ ë¼ì¸(Hold Short Line)\"ì€ ê³µí•­ í™œì£¼ë¡œì—ì„œ í•­ê³µê¸°ê°€ íŠ¹ì • ì§€ì ê¹Œì§€ë§Œ ì§„ì…í•˜ë„ë¡ ì§€ì‹œí•˜ëŠ” ì„ ì…ë‹ˆë‹¤. \n",
      "\n",
      "ë³´í†µ ë‹¤ìŒê³¼ ê°™ì€ ìƒí™©ì—ì„œ ì‚¬ìš©ë©ë‹ˆë‹¤:\n",
      "- í™œì£¼ë¡œ ì ê²€ ì¤‘ì¼ ë•Œ\n",
      "- ë‹¤ë¥¸ í•­ê³µê¸°ì™€ ê°„ê²©ì„ ë‘ê¸° ìœ„í•´\n",
      "- ë‚ ì”¨ ì¡°ê±´ì´ ì¢‹ì§€ ì•Šì„ ë•Œ\n",
      "- ATC(ê´€ì œì†Œ)ì˜ ì•ˆì „ ì§€ì‹œ\n",
      "\n",
      "ì´ ì„ ì„ ë„˜ì–´ì„œë©´ ì•ˆì „ìƒ ë¬¸ì œê°€ ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, íŒŒì¼ëŸ¿ì€ ë°˜ë“œì‹œ ì§€ì‹œë¥¼ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ç”¨æˆ·2å–œæ¬¢éŸ©æ–‡å›å¤\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant. Please be extra concise.\"},\n",
    "        {\"role\": \"user\", \"content\": 'What is a \"hold short line\"?'}\n",
    "    ]},\n",
    "    context=Context(user_id=\"user_2\"),\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea07a9a-289f-4f4c-987c-a76f4818e753",
   "metadata": {},
   "source": [
    "### 3ï¼‰ä½¿ç”¨ `Runtime` ç®¡ç†ä¸Šä¸‹æ–‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8776b008-b2a7-4947-8bed-f51460d37712",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Context:\n",
    "    user_role: str\n",
    "    deployment_env: str\n",
    "\n",
    "@dynamic_prompt\n",
    "def context_aware_prompt(request: ModelRequest) -> str:\n",
    "    # Read from Runtime Context: user role and environment\n",
    "    user_role = request.runtime.context.user_role\n",
    "    env = request.runtime.context.deployment_env\n",
    "\n",
    "    base = \"You are a helpful assistant.\"\n",
    "\n",
    "    if user_role == \"admin\":\n",
    "        base += \"\\nYou can use the get_weather tool.\"\n",
    "    else:\n",
    "        base += \"\\nYou are prohibited from using the get_weather tool.\"\n",
    "\n",
    "    if env == \"production\":\n",
    "        base += \"\\nBe extra careful with any data modifications.\"\n",
    "\n",
    "    return base\n",
    "\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[get_weather],\n",
    "    middleware=[context_aware_prompt],\n",
    "    context_schema=Context,\n",
    "    checkpointer=InMemorySaver(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db1a91c1-f87f-46ce-b6fe-251040867390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "å¹¿å·ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_weather (call_41b1ba3713dd46e8a3cde3b0)\n",
      " Call ID: call_41b1ba3713dd46e8a3cde3b0\n",
      "  Args:\n",
      "    city: å¹¿å·\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_weather\n",
      "\n",
      "It's always sunny in å¹¿å·!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "æ ¹æ®æˆ‘è·å–çš„ä¿¡æ¯ï¼Œå¹¿å·ä»Šå¤©çš„å¤©æ°”æ˜¯æ™´æœ—çš„ã€‚å¦‚æœæ‚¨éœ€è¦æ›´è¯¦ç»†çš„å¤©æ°”ä¿¡æ¯ï¼Œæ¯”å¦‚æ¸©åº¦ã€æ¹¿åº¦æˆ–é£åŠ›ç­‰ï¼Œè¯·å‘Šè¯‰æˆ‘ï¼Œæˆ‘ä¼šå°½åŠ›æä¾›å¸®åŠ©ã€‚\n"
     ]
    }
   ],
   "source": [
    "# åˆ©ç”¨ Runtime ä¸­çš„ä¸¤ä¸ªå˜é‡ï¼ŒåŠ¨æ€æ§åˆ¶ System prompt\n",
    "# å°† user_role è®¾ä¸º adminï¼Œå…è®¸ä½¿ç”¨å¤©æ°”æŸ¥è¯¢å·¥å…·\n",
    "config = {'configurable': {'thread_id': str(uuid.uuid4())}}\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"å¹¿å·ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"}]},\n",
    "    context=Context(user_role=\"admin\", deployment_env=\"production\"),\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d51ba924-4b11-4268-a498-29104a3916bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "å¹¿å·ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "å¯¹ä¸èµ·ï¼Œæˆ‘æ— æ³•è·å–å¤©æ°”ä¿¡æ¯ã€‚è¯·å°è¯•ä½¿ç”¨å…¶ä»–æ–¹å¼æŸ¥è¯¢å¹¿å·çš„å¤©æ°”ï¼Œä¾‹å¦‚æŸ¥çœ‹å¤©æ°”é¢„æŠ¥åº”ç”¨æˆ–ç½‘ç«™ã€‚\n"
     ]
    }
   ],
   "source": [
    "# è‹¥å°† user_role æ”¹ä¸º viewerï¼Œåˆ™æ— æ³•ä½¿ç”¨å¤©æ°”æŸ¥è¯¢å·¥å…·\n",
    "config = {'configurable': {'thread_id': str(uuid.uuid4())}}\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"å¹¿å·ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"}]},\n",
    "    context=Context(user_role=\"viewer\", deployment_env=\"production\"),\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ae08b79-0e58-4d4a-90c9-22e9624a4a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='å¹¿å·ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ', additional_kwargs={}, response_metadata={}, id='58493935-80a8-4f05-818d-4fa3ef684657'),\n",
       " AIMessage(content='æŠ±æ­‰ï¼Œæˆ‘æ— æ³•è·å–å¤©æ°”ä¿¡æ¯ã€‚æ‚¨å¯ä»¥é€šè¿‡å…¶ä»–é€”å¾„æŸ¥è¯¢å¹¿å·ä»Šå¤©çš„å¤©æ°”ï¼Œä¾‹å¦‚ä½¿ç”¨å¤©æ°”åº”ç”¨æˆ–è®¿é—®å¤©æ°”ç½‘ç«™ã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 287, 'total_tokens': 313, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen3-coder-plus', 'system_fingerprint': None, 'id': 'chatcmpl-b3da39f7-8f49-4a63-9794-06bd7578354f', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--5c17667c-38c3-4856-9610-9d6f4cfd4d16-0', usage_metadata={'input_tokens': 287, 'output_tokens': 26, 'total_tokens': 313, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['messages']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705e6d02-152c-4a13-a5fc-60e27113d596",
   "metadata": {},
   "source": [
    "## äºŒã€åŠ¨æ€ä¿®æ”¹æ¶ˆæ¯åˆ—è¡¨\n",
    "\n",
    "LangGraph é¢„åˆ¶äº†åŠ¨æ€ä¿®æ”¹æ¶ˆæ¯åˆ—è¡¨ï¼ˆMessagesï¼‰çš„ä¸­é—´ä»¶ `@wrap_model_call`ã€‚ä¸Šä¸€èŠ‚å·²ç»æ¼”ç¤ºå¦‚ä½•ä» `State`ã€`Store`ã€`Runtime` ä¸­è·å–ä¸Šä¸‹æ–‡ï¼Œæœ¬èŠ‚å°†ä¸å†ä¸€ä¸€æ¼”ç¤ºã€‚åœ¨ä¸‹é¢è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬ä¸»è¦æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ `Runtime` å°†æœ¬åœ°æ–‡ä»¶çš„å†…å®¹æ³¨å…¥æ¶ˆæ¯åˆ—è¡¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc7b4e4a-1dca-4e40-bafa-840373986c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FileContext:\n",
    "    uploaded_files: list[dict]\n",
    "\n",
    "@wrap_model_call\n",
    "def inject_file_context(\n",
    "    request: ModelRequest,\n",
    "    handler: Callable[[ModelRequest], ModelResponse]\n",
    ") -> ModelResponse:\n",
    "    \"\"\"Inject context about files user has uploaded this session.\"\"\"\n",
    "    uploaded_files = request.runtime.context.uploaded_files\n",
    "\n",
    "    try:\n",
    "        base_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    except Exception as e:\n",
    "        import ipynbname\n",
    "        import os\n",
    "        notebook_path = ipynbname.path()\n",
    "        base_dir = os.path.dirname(notebook_path)\n",
    "\n",
    "    file_sections = []\n",
    "    for file in uploaded_files:\n",
    "        name, ftype = \"\", \"\"\n",
    "        path = file.get(\"path\")\n",
    "        if path:\n",
    "            base_filename = os.path.basename(path)\n",
    "            stem, ext = os.path.splitext(base_filename)\n",
    "            name = stem or base_filename\n",
    "            ftype = (ext.lstrip(\".\") if ext else None)\n",
    "\n",
    "            # æ„å»ºæ–‡ä»¶æè¿°å†…å®¹\n",
    "            content_list = [f\"åç§°: {name}\"]\n",
    "            if ftype:\n",
    "                content_list.append(f\"ç±»å‹: {ftype}\")\n",
    "\n",
    "            # è§£æç›¸å¯¹è·¯å¾„ä¸ºç»å¯¹è·¯å¾„\n",
    "            abs_path = path if os.path.isabs(path) else os.path.join(base_dir, path)\n",
    "\n",
    "            # è¯»å–æ–‡ä»¶å†…å®¹\n",
    "            content_block = \"\"\n",
    "            if abs_path and os.path.exists(abs_path):\n",
    "                try:\n",
    "                    with open(abs_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                        content_block = f.read()\n",
    "                except Exception as e:\n",
    "                    content_block = f\"[è¯»å–æ–‡ä»¶é”™è¯¯ '{abs_path}': {e}]\"\n",
    "            else:\n",
    "                content_block = \"[æ–‡ä»¶è·¯å¾„ç¼ºå¤±æˆ–æœªæ‰¾åˆ°]\"\n",
    "\n",
    "            section = (\n",
    "                f\"---\\n\"\n",
    "                f\"{chr(10).join(content_list)}\\n\\n\"\n",
    "                f\"{content_block}\\n\"\n",
    "                f\"---\"\n",
    "            )\n",
    "            file_sections.append(section)\n",
    "\n",
    "        file_context = (\n",
    "            \"å·²åŠ è½½çš„ä¼šè¯æ–‡ä»¶ï¼š\\n\"\n",
    "            f\"{chr(10).join(file_sections)}\"\n",
    "            \"\\nå›ç­”é—®é¢˜æ—¶è¯·å‚è€ƒè¿™äº›æ–‡ä»¶ã€‚\"\n",
    "        )\n",
    "\n",
    "        # Inject file context before recent messages\n",
    "        messages = [  \n",
    "            *request.messages,\n",
    "            {\"role\": \"user\", \"content\": file_context},\n",
    "        ]\n",
    "        request = request.override(messages=messages)  \n",
    "\n",
    "    return handler(request)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    middleware=[inject_file_context],\n",
    "    context_schema=FileContext,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9048a7e0-2131-4841-82f2-b1f7fca1c1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "å…³äºä¸Šæµ·åœ°é“çš„æ— è„¸ä¹˜å®¢ï¼Œæœ‰ä»€ä¹ˆéœ€è¦æ³¨æ„çš„ï¼Ÿ\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "æ ¹æ®ã€Šrule_horrorã€‹æ–‡ä»¶ä¸­çš„â€œ**2. åœ°é“ä¸Šçš„é™Œç”Ÿäºº**â€ä¸€æ¡ï¼Œå…³äºä¸Šæµ·åœ°é“çš„æ— è„¸ä¹˜å®¢ï¼Œä½ éœ€è¦ç‰¹åˆ«æ³¨æ„ä»¥ä¸‹å‡ ç‚¹ï¼š\n",
      "\n",
      "---\n",
      "\n",
      "### ğŸš‡ é‡åˆ°æ— è„¸ä¹˜å®¢æ—¶çš„æ³¨æ„äº‹é¡¹ï¼š\n",
      "\n",
      "1. **æ—¶é—´èƒŒæ™¯**ï¼š  \n",
      "   æ­¤ç°è±¡å‘ç”Ÿåœ¨**åœ°é“è¿è¥ç»“æŸä¹‹å**ï¼Œä½ ä»æ»ç•™åœ¨è½¦å¢å†…æ—¶ã€‚\n",
      "\n",
      "2. **æ— è„¸ä¹˜å®¢çš„è¡Œä¸º**ï¼š  \n",
      "   ä»–ä¼šä½å£°é—®ä½ ï¼šâ€œ**ä½ è¦å»å“ªï¼Ÿ**â€\n",
      "\n",
      "3. **æ­£ç¡®åº”å¯¹æ–¹å¼**ï¼š  \n",
      "   - å¿…é¡»å›ç­”**ä¸€ä¸ªçœŸå®å­˜åœ¨çš„ä¸Šæµ·åœ°å**ï¼ˆå¦‚ï¼šäººæ°‘å¹¿åœºã€å¾å®¶æ±‡ã€é™†å®¶å˜´ç­‰ï¼‰ã€‚  \n",
      "   - å›ç­”å¿…é¡»å‡†ç¡®ä¸”å­˜åœ¨ï¼Œå¦åˆ™åæœä¸¥é‡ã€‚\n",
      "\n",
      "4. **é”™è¯¯è¡Œä¸ºåŠåæœ**ï¼š  \n",
      "   - è‹¥ä½ **ä¿æŒæ²‰é»˜**ï¼Œæˆ–  \n",
      "   - å›ç­”äº†ä¸€ä¸ª**ä¸å­˜åœ¨çš„åœ°å**ï¼ˆä¾‹å¦‚è™šæ„åœ°ç‚¹æˆ–éä¸Šæµ·åœ°åï¼‰ï¼Œ  \n",
      "   â¤ ä½ å°†åœ¨è½¦å¢å†…**çœ‹åˆ°è‡ªå·±çš„å°¸ä½“**ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### âš ï¸ ç”Ÿå­˜è¦ç‚¹æ€»ç»“ï¼š\n",
      "\n",
      "- **ä¸è¦æ²‰é»˜**ã€‚\n",
      "- **ä¸è¦æ’’è°**ã€‚\n",
      "- **å¿…é¡»è¯´çœŸåœ°å**ã€‚\n",
      "\n",
      "è¿è€…ï¼Œå°†é¢ä¸´æå…¶ææ€–çš„åæœã€‚\n",
      "\n",
      "--- \n",
      "\n",
      "å¦‚ä½ åœ¨æ·±å¤œä¹˜åä¸Šæµ·åœ°é“ï¼Œè¯·åŠ¡å¿…ç¡®ä¿åœ¨è¿è¥æ—¶é—´å†…ç¦»å¼€ï¼Œé¿å…é­é‡æ­¤ç±»å¼‚å¸¸äº‹ä»¶ã€‚\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"å…³äºä¸Šæµ·åœ°é“çš„æ— è„¸ä¹˜å®¢ï¼Œæœ‰ä»€ä¹ˆéœ€è¦æ³¨æ„çš„ï¼Ÿ\",\n",
    "        }],\n",
    "    },\n",
    "    context=FileContext(uploaded_files=[{\"path\": \"./docs/rule_horror.md\"}]),\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59498b8d-9b5d-4cb3-bc86-0230e76a8121",
   "metadata": {},
   "source": [
    "## ä¸‰ã€åœ¨å·¥å…·ä¸­ä½¿ç”¨ä¸Šä¸‹æ–‡\n",
    "\n",
    "ä¸‹é¢ï¼Œæˆ‘ä»¬å°è¯•åœ¨å·¥å…·ä¸­ä½¿ç”¨å­˜å‚¨åœ¨ `SqliteStore` ä¸­çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a33e3357-71e3-4ae3-a956-9e6ad0076a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ é™¤SQLiteæ•°æ®åº“\n",
    "if os.path.exists(\"user-info.db\"):\n",
    "    os.remove(\"user-info.db\")\n",
    "\n",
    "# åˆ›å»ºSQLiteå­˜å‚¨\n",
    "conn = sqlite3.connect(\"user-info.db\", check_same_thread=False, isolation_level=None)\n",
    "conn.execute(\"PRAGMA journal_mode=WAL;\")\n",
    "conn.execute(\"PRAGMA busy_timeout = 30000;\")\n",
    "\n",
    "store = SqliteStore(conn)\n",
    "\n",
    "# é¢„ç½®ä¸¤æ¡ç”¨æˆ·ä¿¡æ¯\n",
    "store.put((\"user_info\",), \"æŸ³å¦‚çƒŸ\", {\"description\": \"æ¸…å†·æ‰å¥³ï¼Œèº«æ€€ç»æŠ€ï¼Œä¸ºå¯»èº«ä¸–ä¹‹è°œè¸å…¥æ±Ÿæ¹–ã€‚\", \"birthplace\": \"å´å…´å¿\"})\n",
    "store.put((\"user_info\",), \"è‹æ…•ç™½\", {\"description\": \"å­¤å‚²å‰‘å®¢ï¼Œå‰‘æ³•è¶…ç¾¤ï¼ŒèƒŒè´Ÿå®¶æ—è¡€ä»‡ï¼Œéšäºå¸‚äº•è¿½å¯»çœŸç›¸ã€‚\", \"birthplace\": \"æ­å¿\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dd8c15-f80a-4885-9477-37d84bbf9495",
   "metadata": {},
   "source": [
    "### 1ï¼‰åŸºç¡€ç”¨ä¾‹\n",
    "\n",
    "ä½¿ç”¨ `ToolRuntime`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de7547ce-963e-48bf-9855-ab32521c034e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def fetch_user_data(\n",
    "    user_id: str,\n",
    "    runtime: ToolRuntime\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Fetch user information from the in-memory store.\n",
    "\n",
    "    :param user_id: The unique identifier of the user.\n",
    "    :param runtime: The tool runtime context injected by the framework.\n",
    "    :return: The user's description string if found; an empty string otherwise.\n",
    "    \"\"\"\n",
    "    store = runtime.store\n",
    "    user_info = store.get((\"user_info\",), user_id)\n",
    "\n",
    "    user_desc = \"\"\n",
    "    if user_info:\n",
    "        user_desc = user_info.value.get(\"description\", \"\")\n",
    "\n",
    "    return user_desc\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[fetch_user_data],\n",
    "    store=store,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60289d99-0235-464c-837c-407065b0096d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "äº”åˆ†é’Ÿä¹‹å†…ï¼Œæˆ‘è¦æŸ³å¦‚çƒŸçš„å…¨éƒ¨ä¿¡æ¯\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  fetch_user_data (call_c4aa91d94b9e443fbabe0941)\n",
      " Call ID: call_c4aa91d94b9e443fbabe0941\n",
      "  Args:\n",
      "    user_id: æŸ³å¦‚çƒŸ\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: fetch_user_data\n",
      "\n",
      "æ¸…å†·æ‰å¥³ï¼Œèº«æ€€ç»æŠ€ï¼Œä¸ºå¯»èº«ä¸–ä¹‹è°œè¸å…¥æ±Ÿæ¹–ã€‚\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "æ ¹æ®æ‚¨çš„è¦æ±‚ï¼Œè¿™æ˜¯å…³äºæŸ³å¦‚çƒŸçš„ä¿¡æ¯ï¼š\n",
      "\n",
      "æŸ³å¦‚çƒŸæ˜¯ä¸€ä½æ¸…å†·æ‰å¥³ï¼Œä¸ä»…æ‰åæ¨ªæº¢è€Œä¸”èº«æ€€ç»æŠ€ã€‚å¥¹ä¸ºäº†æ¢å¯»è‡ªå·±çš„èº«ä¸–ä¹‹è°œè€Œè¸å…¥äº†æ±Ÿæ¹–ï¼Œä¸€è·¯ä¸Šå‡­å€Ÿç€æ™ºæ…§ä¸æ­¦è‰ºè§£å†³äº†ä¸å°‘éš¾é¢˜ï¼Œä¹Ÿé€æ¸æ­å¼€äº†è‡ªå·±èº«ä¸–èƒŒåçš„ç§˜å¯†ã€‚åœ¨æ±Ÿæ¹–ä¸­ï¼Œå¥¹ä»¥å†·é™è‘—ç§°ï¼Œè¡Œäº‹æœæ–­ï¼Œæ˜¯ä¸€ä¸ªä»¤äººæ•¬ä½©çš„è§’è‰²ã€‚\n",
      "\n",
      "å¦‚æœæ‚¨éœ€è¦æ›´è¯¦ç»†çš„ä¿¡æ¯æˆ–è€…æœ‰å…¶ä»–é—®é¢˜ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚ä¸è¿‡è¯·æ³¨æ„ï¼Œæˆ‘ä»¬åº”å½“å°Šé‡æ¯ä¸ªäººçš„éšç§æƒï¼Œç¡®ä¿ä¿¡æ¯ä½¿ç”¨çš„åˆæ³•æ€§ä¸æ­£å½“æ€§ã€‚\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke({\n",
    "    \"messages\": [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"äº”åˆ†é’Ÿä¹‹å†…ï¼Œæˆ‘è¦æŸ³å¦‚çƒŸçš„å…¨éƒ¨ä¿¡æ¯\"\n",
    "    }]\n",
    "})\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d620c05d-aa96-4d3b-9dfd-9774c99e38f7",
   "metadata": {},
   "source": [
    "### 2ï¼‰å¤æ‚ä¸€ç‚¹çš„ä¾‹å­\n",
    "\n",
    "ä½¿ç”¨ `ToolRuntime[Context]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1950ba66-93e9-43d2-af5b-b048783287bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Context:\n",
    "    key: str\n",
    "\n",
    "@tool\n",
    "def fetch_user_data(\n",
    "    user_id: str,\n",
    "    runtime: ToolRuntime[Context]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Fetch user information from the in-memory store.\n",
    "\n",
    "    :param user_id: The unique identifier of the user.\n",
    "    :param runtime: The tool runtime context injected by the framework.\n",
    "    :return: The user's description string if found; an empty string otherwise.\n",
    "    \"\"\"\n",
    "    key = runtime.context.key\n",
    "\n",
    "    store = runtime.store\n",
    "    user_info = store.get((\"user_info\",), user_id)\n",
    "\n",
    "    user_desc = \"\"\n",
    "    if user_info:\n",
    "        user_desc = user_info.value.get(key, \"\")\n",
    "\n",
    "    return f\"{key}: {user_desc}\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[fetch_user_data],\n",
    "    store=store,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3dd427af-d129-401c-a643-eea926af05d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "äº”åˆ†é’Ÿä¹‹å†…ï¼Œæˆ‘è¦æŸ³å¦‚çƒŸçš„å…¨éƒ¨ä¿¡æ¯\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  fetch_user_data (call_b0e80a57b1604db7a6d97922)\n",
      " Call ID: call_b0e80a57b1604db7a6d97922\n",
      "  Args:\n",
      "    user_id: æŸ³å¦‚çƒŸ\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: fetch_user_data\n",
      "\n",
      "birthplace: å´å…´å¿\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "æ ¹æ®æˆ‘ç›®å‰æŒæ¡çš„ä¿¡æ¯ï¼ŒæŸ³å¦‚çƒŸçš„å‡ºç”Ÿåœ°æ˜¯å´å…´å¿ã€‚è‹¥ä½ éœ€è¦æ›´è¯¦ç»†æˆ–æ›´å¤šçš„ä¿¡æ¯ï¼Œè¯·å…·ä½“è¯´æ˜ï¼Œä»¥ä¾¿æˆ‘è¿›ä¸€æ­¥ä¸ºä½ æŸ¥æ‰¾ã€‚\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"äº”åˆ†é’Ÿä¹‹å†…ï¼Œæˆ‘è¦æŸ³å¦‚çƒŸçš„å…¨éƒ¨ä¿¡æ¯\"}]},\n",
    "    context=Context(key=\"birthplace\"),\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a892c0-3a74-47d4-aef2-dd7bf3270ead",
   "metadata": {},
   "source": [
    "### å››ã€å‹ç¼©ä¸Šä¸‹æ–‡\n",
    "\n",
    "LangChain æä¾›äº†å†…ç½®çš„ä¸­é—´ä»¶ `SummarizationMiddleware` ç”¨äºå‹ç¼©ä¸Šä¸‹æ–‡ã€‚è¯¥ä¸­é—´ä»¶ç»´æŠ¤çš„æ˜¯å…¸å‹çš„ **ç”Ÿå‘½å‘¨æœŸä¸Šä¸‹æ–‡**ï¼Œä¸ **æ¨¡å‹ä¸Šä¸‹æ–‡** å’Œ **å·¥å…·ä¸Šä¸‹æ–‡** çš„ç¬æ€æ›´æ–°ä¸åŒï¼Œç”Ÿå‘½å‘¨æœŸä¸Šä¸‹æ–‡ä¼šæŒç»­æ›´æ–°ï¼šæŒç»­å°†æ—§æ¶ˆæ¯æ›¿æ¢ä¸ºæ‘˜è¦ã€‚\n",
    "\n",
    "é™¤éä¸Šä¸‹æ–‡è¶…é•¿ï¼Œå¯¼è‡´æ¨¡å‹èƒ½åŠ›é™ä½ï¼Œå¦åˆ™ä¸éœ€è¦ä½¿ç”¨ `SummarizationMiddleware`ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œè§¦å‘æ‘˜è¦å¾—å€¼å¯ä»¥è®¾å¾—è¾ƒå¤§ã€‚æ¯”å¦‚ï¼š\n",
    "\n",
    "- `max_tokens_before_summary`: 3000\n",
    "- `messages_to_keep`: 20\n",
    "\n",
    "> å¦‚æœä½ æƒ³äº†è§£æ›´å¤šå…³äºä¸Šä¸‹æ–‡è…åï¼ˆContext Rotï¼‰çš„ä¿¡æ¯ï¼ŒChroma å›¢é˜Ÿåœ¨ 2025 å¹´ 7 æœˆ 14 æ—¥å‘å¸ƒçš„ [*Context Rot: How Increasing Input Tokens Impacts LLM Performance*](https://research.trychroma.com/context-rot)ï¼Œç³»ç»Ÿæ€§åœ°æ­ç¤ºäº†é•¿ä¸Šä¸‹æ–‡å¯¼è‡´æ¨¡å‹æ€§èƒ½é€€åŒ–çš„ç°è±¡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c75a7d59-9edf-4a00-af8a-3a6d06d6f27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6038/2515064759.py:9: DeprecationWarning: max_tokens_before_summary is deprecated. Use trigger=('tokens', value) instead.\n",
      "  SummarizationMiddleware(\n",
      "/tmp/ipykernel_6038/2515064759.py:9: DeprecationWarning: messages_to_keep is deprecated. Use keep=('messages', value) instead.\n",
      "  SummarizationMiddleware(\n"
     ]
    }
   ],
   "source": [
    "# åˆ›å»ºçŸ­æœŸè®°å¿†\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "# åˆ›å»ºå¸¦å†…ç½®æ‘˜è¦ä¸­é—´ä»¶çš„Agent\n",
    "# ä¸ºäº†è®©é…ç½®èƒ½åœ¨æˆ‘ä»¬çš„ä¾‹å­é‡Œç”Ÿæ•ˆï¼Œè¿™é‡Œçš„è§¦å‘å€¼è®¾å¾—å¾ˆå°\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    middleware=[\n",
    "        SummarizationMiddleware(\n",
    "            model=llm,\n",
    "            max_tokens_before_summary=40,  # Trigger summarization at 40 tokens\n",
    "            messages_to_keep=1,  # Keep last 1 messages after summary\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91068064-ef38-4ae3-841b-5bc7be34c624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Here is a summary of the conversation to date:\n",
      "\n",
      "å¹¿å·å¤©æ°”å¾ˆå¥½ã€‚ç”¨æˆ·è¯¢é—®åƒä»€ä¹ˆå¥½ï¼Œå»ºè®®åƒé¦™èŒ…é³—é±¼ç…²ã€‚ç”¨æˆ·è¯¢é—®é¦™èŒ…æ˜¯ä»€ä¹ˆï¼Œè§£é‡Šé¦™èŒ…åˆåæŸ æª¬è‰ï¼Œå¸¸è§äºæ³°å¼å†¬é˜´åŠŸæ±¤ã€è¶Šå—çƒ¤è‚‰ç­‰èœè‚´ä¸­ã€‚\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "auv é‚£è¿˜ç­‰ä»€ä¹ˆï¼Œå’±åƒå»å§\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "å“ˆå“ˆï¼Œçœ‹æ¥ä½ å·²ç»è¿«ä¸åŠå¾…äº†ï¼ğŸ˜„\n",
      "\n",
      "ä¸è¿‡æˆ‘å¾—æé†’ä¸€ä¸‹ï¼Œæˆ‘æ˜¯AIåŠ©æ‰‹ï¼Œæ²¡æ³•çœŸçš„å’Œä½ ä¸€èµ·å»åƒé¥­ã€‚ä½†æˆ‘å¯ä»¥å¸®ä½ ï¼š\n",
      "\n",
      "- æ¨èé™„è¿‘æœ‰è¿™é“èœçš„é¤å…\n",
      "- æä¾›åˆ¶ä½œé¦™èŒ…é³—é±¼ç…²çš„é£Ÿè°±\n",
      "- ä»‹ç»æ›´å¤šå…³äºé¦™èŒ…çš„æ–™ç†çŸ¥è¯†\n",
      "\n",
      "ä½ æƒ³åšä»€ä¹ˆå‘¢ï¼Ÿæ˜¯è¦æ‰¾é¤å…è¿˜æ˜¯æƒ³è‡ªå·±åŠ¨æ‰‹åšï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke(\n",
    "    {\"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"å¹¿å·ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"å¹¿å·å¤©æ°”å¾ˆå¥½\"},\n",
    "        {\"role\": \"user\", \"content\": \"åƒç‚¹ä»€ä¹ˆå¥½å‘¢\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"è¦ä¸è¦åƒé¦™èŒ…é³—é±¼ç…²\"},\n",
    "        {\"role\": \"user\", \"content\": \"é¦™èŒ…æ˜¯ä»€ä¹ˆ\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"é¦™èŒ…åˆåæŸ æª¬è‰ï¼Œå¸¸è§äºæ³°å¼å†¬é˜´åŠŸæ±¤ã€è¶Šå—çƒ¤è‚‰\"},\n",
    "        {\"role\": \"user\", \"content\": \"auv é‚£è¿˜ç­‰ä»€ä¹ˆï¼Œå’±åƒå»å§\"},\n",
    "    ]},\n",
    "    checkpointer=checkpointer,\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725262df-d313-4499-ad09-fe12ac9c7955",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dive-langgraph-py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
